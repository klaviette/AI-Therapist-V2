{"cells":[{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-09-06T18:18:04.865042Z","iopub.status.busy":"2023-09-06T18:18:04.864650Z","iopub.status.idle":"2023-09-06T18:18:04.871743Z","shell.execute_reply":"2023-09-06T18:18:04.870057Z","shell.execute_reply.started":"2023-09-06T18:18:04.865013Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import os\n","import cv2\n","\n","# Major concepts of this program were inspired by following Samson Zhang's NN from Scratch Youtube video\n","# I created my own datasets, all images were drawn by hand\n","# I found the script below to turn a set of images into a np array, and tweaked it a little"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-09-06T18:18:04.874308Z","iopub.status.busy":"2023-09-06T18:18:04.873824Z","iopub.status.idle":"2023-09-06T18:18:09.451638Z","shell.execute_reply":"2023-09-06T18:18:09.450549Z","shell.execute_reply.started":"2023-09-06T18:18:04.874263Z"},"trusted":true},"outputs":[],"source":["DATADIR = \"/kaggle/input/trainingdata/TrainingData\"\n","CATEGORIES = [\"Happy\", \"Sad\"]\n","\n","data = []\n","IMG_SIZE = 50\n","\n","## will create a npy array that stores our training data\n","def create_training_data():\n","    \n","    class_num = 0\n","    \n","    for category in CATEGORIES:\n","        \n","        ## this for loop iterates through each image in my uploaded Kaggle dataset and appends it to a 2D npy array\n","        \n","        path = os.path.join(DATADIR, category)\n","        for img in os.listdir(path):\n","            img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n","            new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n","            flattened_pixels = new_array.flatten().tolist()  # Flatten and convert to a Python list\n","\n","            data.append([class_num] + flattened_pixels)\n","        class_num += 1\n","            \n","create_training_data()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-06T18:18:09.454118Z","iopub.status.busy":"2023-09-06T18:18:09.453474Z","iopub.status.idle":"2023-09-06T18:18:10.239151Z","shell.execute_reply":"2023-09-06T18:18:10.237904Z","shell.execute_reply.started":"2023-09-06T18:18:09.454073Z"},"trusted":true},"outputs":[],"source":["data = np.array(data)\n","m, n = data.shape\n","\n","## it is important to shuffle data, because each class was in a different directory\n","## create_training_data() was done in order so the data array would be [0,0,0, ... ,1,1,1]\n","np.random.shuffle(data)\n","\n","## this set of array manipulation separates the labels from actual image pixel data\n","## we transpose the data_dev and data_train arrays to allow for matrix multiplication\n","data_dev = data[0:20].T\n","Y_dev = data_dev[0]\n","X_dev = data_dev[1:n]\n","X_dev = X_dev / 255.\n","\n","data_train = data[20:m].T\n","Y_train = data_train[0]\n","X_train = data_train[1:n]\n","X_train = X_train / 255.\n","_,m_train = X_train.shape\n","\n","\n","## this simple neural network will only have one hidden layer and one output layer (so 3 layers total)\n","## all weights and biases are set to a random number between -0.5 and 0.5\n","def init_params():\n","    W1 = np.random.rand(10, 2500) - 0.5\n","    b1 = np.random.rand(10, 1) - 0.5\n","    W2 = np.random.rand(2, 10) - 0.5\n","    b2 = np.random.rand(2, 1) - 0.5\n","    \n","    return W1, b1, W2, b2\n","\n","\n","## ReLU and softmax are some good functions to emphasize the change between each iteration\n","## Samson also used these as examples in his video\n","def ReLU(Z):\n","    return np.maximum(0, Z)\n","\n","def softmax(Z):\n","    return np.exp(Z) / sum(np.exp(Z))\n","\n","## Applies weights and biases to an epoch of images (all training images are in the data array, passed as X here)\n","def forward_prop(W1, b1, W2, b2, X):\n","    Z1 = W1.dot(X) + b1\n","    A1 = ReLU(Z1)\n","    Z2 = W2.dot(A1) + b2\n","    A2 = softmax(Z2)\n","    \n","    return Z1, A1, Z2, A2\n","\n","## \n","def one_hot(Y):\n","    one_hot_Y = np.zeros((Y.size, Y.max() + 1))\n","    one_hot_Y[np.arange(Y.size), Y] = 1\n","    one_hot_Y = one_hot_Y.T\n","    return one_hot_Y\n","\n","def deriv_ReLU(Z):\n","    return Z > 0\n","\n","def back_prop(Z1, A1, Z2, A2, W2, X, Y):  \n","    m = Y.size\n","    \n","    one_hot_Y = one_hot(Y)\n","    \n","    dZ2 = A2 - one_hot_Y\n","    dW2 = 1 / m * dZ2.dot(A1.T)\n","    db2 = 1 / m * np.sum(dZ2, axis=1).reshape(-1, 1)\n","    dZ1 = W2.T.dot(dZ2) * deriv_ReLU(Z1)\n","    dW1 = 1 / m * dZ1.dot(X.T)\n","    db1 = 1 / m * np.sum(dZ1, axis=1).reshape(-1, 1)\n","    \n","    return dW1, db1, dW2, db2\n","\n","def update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha):\n","    W1 = W1 - alpha * dW1\n","    b1 = b1 - alpha * db1\n","    W2 = W2 - alpha * dW2\n","    b2 = b2 - alpha * db2\n","    \n","    return W1, b1, W2, b2\n","\n","\n","\n","def get_predictions(A2):\n","    return np.argmax(A2, 0)\n","\n","def get_accuracy(predictions, Y):\n","    return np.sum(predictions == Y) / Y.size\n","\n","def gradient_descent(X, Y, iterations, alpha):\n","    W1, b1, W2, b2 = init_params()\n","    m = len(Y)\n","\n","\n","    for i in range(iterations):\n","\n","        if(i%1==0):\n","            permutation = np.random.permutation(m)\n","            X_shuffled = X.T[permutation]\n","            Y_shuffled = Y[permutation]\n","            alpha *= 0.9999\n","\n","        Z1, A1, Z2, A2 = forward_prop(W1, b1, W2, b2, X_shuffled.T)\n","        dW1, db1, dW2, db2 = back_prop(Z1, A1, Z2, A2, W2, X_shuffled.T, Y_shuffled)\n","        W1, b1, W2, b2 = update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha)\n","\n","        if i % 1000 == 0:\n","            print(\"Iteration: \", i)\n","            predictions = get_predictions(A2)\n","            accuracy = get_accuracy(predictions, Y_shuffled) #accuracy = get_accuracy(predictions, Y_shuffled)\n","            print(\"Accuracy: \", accuracy)\n","\n","    return W1, b1, W2, b2"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-09-06T18:18:10.241875Z","iopub.status.busy":"2023-09-06T18:18:10.241481Z","iopub.status.idle":"2023-09-06T18:39:12.166702Z","shell.execute_reply":"2023-09-06T18:39:12.165057Z","shell.execute_reply.started":"2023-09-06T18:18:10.241842Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Iteration:  0\n","Accuracy:  0.4991717283268912\n","Iteration:  1000\n","Accuracy:  0.5400331308669244\n","Iteration:  2000\n","Accuracy:  0.5610160132523467\n","Iteration:  3000\n","Accuracy:  0.5759249033683048\n","Iteration:  4000\n","Accuracy:  0.5963556046383214\n","Iteration:  5000\n","Accuracy:  0.6145775814467145\n","Iteration:  6000\n","Accuracy:  0.6322473771397018\n","Iteration:  7000\n","Accuracy:  0.6488128106018775\n","Iteration:  8000\n","Accuracy:  0.6664826062948647\n","Iteration:  9000\n","Accuracy:  0.6858089453340696\n","Iteration:  10000\n","Accuracy:  0.6929872998343457\n","Iteration:  11000\n","Accuracy:  0.7078961899503037\n","Iteration:  12000\n","Accuracy:  0.72170071783545\n","Iteration:  13000\n","Accuracy:  0.7310877967973495\n","Iteration:  14000\n","Accuracy:  0.7410270568746549\n","Iteration:  15000\n","Accuracy:  0.7548315847598012\n","Iteration:  16000\n","Accuracy:  0.7614577581446714\n","Iteration:  17000\n","Accuracy:  0.7702926559911651\n","Iteration:  18000\n","Accuracy:  0.7758144671452236\n","Iteration:  19000\n","Accuracy:  0.7774710104914412\n","Iteration:  20000\n","Accuracy:  0.781888459414688\n","Iteration:  21000\n","Accuracy:  0.7863059083379348\n","Iteration:  22000\n","Accuracy:  0.7918277194919934\n","Iteration:  23000\n","Accuracy:  0.7967973495306461\n","Iteration:  24000\n","Accuracy:  0.8023191606847045\n","Iteration:  25000\n","Accuracy:  0.804527885146328\n","Iteration:  26000\n","Accuracy:  0.8028713418001104\n","Iteration:  27000\n","Accuracy:  0.8056322473771397\n","Iteration:  28000\n","Accuracy:  0.8067366096079515\n","Iteration:  29000\n","Accuracy:  0.8078409718387631\n"]}],"source":["W1, b1, W2, b2 = gradient_descent(X_train, Y_train, 30000, 0.025)"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2023-09-06T18:44:16.004117Z","iopub.status.busy":"2023-09-06T18:44:16.003670Z","iopub.status.idle":"2023-09-06T18:44:21.403051Z","shell.execute_reply":"2023-09-06T18:44:21.401753Z","shell.execute_reply.started":"2023-09-06T18:44:16.004081Z"},"trusted":true},"outputs":[],"source":["#creates another testing set\n","\n","DATADIR = \"/kaggle/input/trainingdata/TrainingData\"\n","CATEGORIES = [\"Happy\", \"Sad\"]\n","\n","# -- switch between testing sets\n","\n","#DATADIR = \"/kaggle/input\"\n","#CATEGORIES = [\"testing\", \"testing2\"]\n","\n","data = []\n","IMG_SIZE = 50\n","\n","def create_training_data():\n","    \n","    class_num = 0\n","    \n","    for category in CATEGORIES:\n","        path = os.path.join(DATADIR, category)  # path to our files\n","        for img in os.listdir(path):\n","            img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n","            new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n","            flattened_pixels = new_array.flatten().tolist()  # Flatten and convert to a Python list\n","\n","            data.append([class_num] + flattened_pixels)\n","        class_num += 1\n","            \n","create_training_data()\n","\n","data = np.array(data)\n","m, n = data.shape\n","np.random.shuffle(data) # shuffle before splitting into dev and training sets\n","\n","data_t = data[0:180].T\n","Y_t = data_t[0]\n","X_t = data_t[1:n]\n","X_t = X_t / 255."]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-09-08T01:00:28.544743Z","iopub.status.busy":"2023-09-08T01:00:28.543911Z","iopub.status.idle":"2023-09-08T01:00:29.103699Z","shell.execute_reply":"2023-09-08T01:00:29.101510Z","shell.execute_reply.started":"2023-09-08T01:00:28.544685Z"},"trusted":true},"outputs":[{"ename":"NameError","evalue":"name 'W1' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[1], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m3\u001b[39m):\n\u001b[0;32m---> 19\u001b[0m     test_prediction(i, \u001b[43mW1\u001b[49m, b1, W2, b2)\n\u001b[1;32m     22\u001b[0m dev_predictions \u001b[38;5;241m=\u001b[39m make_predictions(X_t, W1, b1, W2, b2)\n\u001b[1;32m     23\u001b[0m get_accuracy(dev_predictions, Y_t)\n","\u001b[0;31mNameError\u001b[0m: name 'W1' is not defined"]}],"source":["def make_predictions(X, W1, b1, W2, b2):\n","    _, _, _, A2 = forward_prop(W1, b1, W2, b2, X)\n","    predictions = get_predictions(A2)\n","    return predictions\n","\n","def test_prediction(index, W1, b1, W2, b2):\n","    current_image = X_t[:, index, None]\n","    prediction = make_predictions(X_t[:, index, None], W1, b1, W2, b2)\n","    label = Y_t[index]\n","    print(\"Prediction: \", prediction)\n","    print(\"Label: \", label)\n","    \n","    current_image = current_image.reshape((50, 50)) * 255\n","    plt.gray()\n","    plt.imshow(current_image, interpolation='nearest')\n","    plt.show()\n","    \n","for i in range(3):\n","    test_prediction(i, W1, b1, W2, b2)\n","\n","\n","dev_predictions = make_predictions(X_t, W1, b1, W2, b2)\n","get_accuracy(dev_predictions, Y_t)"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2023-09-06T18:44:45.624707Z","iopub.status.busy":"2023-09-06T18:44:45.624300Z","iopub.status.idle":"2023-09-06T18:44:45.631903Z","shell.execute_reply":"2023-09-06T18:44:45.630808Z","shell.execute_reply.started":"2023-09-06T18:44:45.624672Z"},"trusted":true},"outputs":[],"source":["# saves numpy arrays Weights and Biases for use in forward_prop() to make predictions\n","np.save('Weights1.npy', W1)\n","np.save('Biases1.npy', b1)\n","np.save('Weights2.npy', W2)\n","np.save('Biases2.npy', b2)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
