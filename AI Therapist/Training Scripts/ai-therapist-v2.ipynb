{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os\nimport cv2\n\n# The majority of this program was inspired by following Samson Zhang's NN from Scratch video\n# I created my own datasets, all images were drawn by hand\n# I found the sctipt below to turn a set of images into a np array, and tweaked it a little","metadata":{"execution":{"iopub.status.busy":"2023-09-06T18:18:04.864650Z","iopub.execute_input":"2023-09-06T18:18:04.865042Z","iopub.status.idle":"2023-09-06T18:18:04.871743Z","shell.execute_reply.started":"2023-09-06T18:18:04.865013Z","shell.execute_reply":"2023-09-06T18:18:04.870057Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"DATADIR = \"/kaggle/input/trainingdata/TrainingData\"\nCATEGORIES = [\"Happy\", \"Sad\"]\n\ndata = []\nIMG_SIZE = 50\n\ndef create_training_data():\n    \n    class_num = 0\n    \n    for category in CATEGORIES:\n        path = os.path.join(DATADIR, category)  # path to our files\n        for img in os.listdir(path):\n            img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n            new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n            flattened_pixels = new_array.flatten().tolist()  # Flatten and convert to a Python list\n\n            data.append([class_num] + flattened_pixels)\n        class_num += 1\n            \ncreate_training_data()","metadata":{"execution":{"iopub.status.busy":"2023-09-06T18:18:04.873824Z","iopub.execute_input":"2023-09-06T18:18:04.874308Z","iopub.status.idle":"2023-09-06T18:18:09.451638Z","shell.execute_reply.started":"2023-09-06T18:18:04.874263Z","shell.execute_reply":"2023-09-06T18:18:09.450549Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"data = np.array(data)\nm, n = data.shape\nnp.random.shuffle(data) # shuffle before splitting into dev and training sets\n\ndata_dev = data[0:20].T\nY_dev = data_dev[0]\nX_dev = data_dev[1:n]\nX_dev = X_dev / 255.\n\ndata_train = data[20:m].T\nY_train = data_train[0]\nX_train = data_train[1:n]\nX_train = X_train / 255.\n_,m_train = X_train.shape\n\n\n\ndef init_params():\n    W1 = np.random.rand(10, 2500) - 0.5\n    b1 = np.random.rand(10, 1) - 0.5\n    W2 = np.random.rand(2, 10) - 0.5\n    b2 = np.random.rand(2, 1) - 0.5\n    \n    return W1, b1, W2, b2\n\ndef ReLU(Z):\n    return np.maximum(0, Z)\n\ndef softmax(Z):\n    return np.exp(Z) / sum(np.exp(Z))\n\ndef forward_prop(W1, b1, W2, b2, X):\n    Z1 = W1.dot(X) + b1\n    A1 = ReLU(Z1)\n    Z2 = W2.dot(A1) + b2\n    A2 = softmax(Z2)\n    \n    return Z1, A1, Z2, A2\n\ndef one_hot(Y):\n    one_hot_Y = np.zeros((Y.size, Y.max() + 1))\n    one_hot_Y[np.arange(Y.size), Y] = 1\n    one_hot_Y = one_hot_Y.T\n    return one_hot_Y\n\ndef deriv_ReLU(Z):\n    return Z > 0\n\ndef back_prop(Z1, A1, Z2, A2, W2, X, Y):  \n    m = Y.size\n    \n    one_hot_Y = one_hot(Y)\n    \n    dZ2 = A2 - one_hot_Y\n    dW2 = 1 / m * dZ2.dot(A1.T)\n    db2 = 1 / m * np.sum(dZ2, axis=1).reshape(-1, 1)\n    dZ1 = W2.T.dot(dZ2) * deriv_ReLU(Z1)\n    dW1 = 1 / m * dZ1.dot(X.T)\n    db1 = 1 / m * np.sum(dZ1, axis=1).reshape(-1, 1)\n    \n    return dW1, db1, dW2, db2\n\ndef update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha):\n    W1 = W1 - alpha * dW1\n    b1 = b1 - alpha * db1\n    W2 = W2 - alpha * dW2\n    b2 = b2 - alpha * db2\n    \n    return W1, b1, W2, b2\n\n\n\ndef get_predictions(A2):\n    return np.argmax(A2, 0)\n\ndef get_accuracy(predictions, Y):\n    return np.sum(predictions == Y) / Y.size\n\ndef gradient_descent(X, Y, iterations, alpha):\n    W1, b1, W2, b2 = init_params()\n    m = len(Y)\n\n\n    for i in range(iterations):\n\n        if(i%1==0):\n            permutation = np.random.permutation(m)\n            X_shuffled = X.T[permutation]\n            Y_shuffled = Y[permutation]\n            alpha *= 0.9999\n\n        Z1, A1, Z2, A2 = forward_prop(W1, b1, W2, b2, X_shuffled.T)\n        dW1, db1, dW2, db2 = back_prop(Z1, A1, Z2, A2, W2, X_shuffled.T, Y_shuffled)\n        W1, b1, W2, b2 = update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha)\n\n        if i % 1000 == 0:\n            print(\"Iteration: \", i)\n            predictions = get_predictions(A2)\n            accuracy = get_accuracy(predictions, Y_shuffled) #accuracy = get_accuracy(predictions, Y_shuffled)\n            print(\"Accuracy: \", accuracy)\n\n    return W1, b1, W2, b2","metadata":{"execution":{"iopub.status.busy":"2023-09-06T18:18:09.453474Z","iopub.execute_input":"2023-09-06T18:18:09.454118Z","iopub.status.idle":"2023-09-06T18:18:10.239151Z","shell.execute_reply.started":"2023-09-06T18:18:09.454073Z","shell.execute_reply":"2023-09-06T18:18:10.237904Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"W1, b1, W2, b2 = gradient_descent(X_train, Y_train, 30000, 0.025)","metadata":{"execution":{"iopub.status.busy":"2023-09-06T18:18:10.241481Z","iopub.execute_input":"2023-09-06T18:18:10.241875Z","iopub.status.idle":"2023-09-06T18:39:12.166702Z","shell.execute_reply.started":"2023-09-06T18:18:10.241842Z","shell.execute_reply":"2023-09-06T18:39:12.165057Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Iteration:  0\nAccuracy:  0.4991717283268912\nIteration:  1000\nAccuracy:  0.5400331308669244\nIteration:  2000\nAccuracy:  0.5610160132523467\nIteration:  3000\nAccuracy:  0.5759249033683048\nIteration:  4000\nAccuracy:  0.5963556046383214\nIteration:  5000\nAccuracy:  0.6145775814467145\nIteration:  6000\nAccuracy:  0.6322473771397018\nIteration:  7000\nAccuracy:  0.6488128106018775\nIteration:  8000\nAccuracy:  0.6664826062948647\nIteration:  9000\nAccuracy:  0.6858089453340696\nIteration:  10000\nAccuracy:  0.6929872998343457\nIteration:  11000\nAccuracy:  0.7078961899503037\nIteration:  12000\nAccuracy:  0.72170071783545\nIteration:  13000\nAccuracy:  0.7310877967973495\nIteration:  14000\nAccuracy:  0.7410270568746549\nIteration:  15000\nAccuracy:  0.7548315847598012\nIteration:  16000\nAccuracy:  0.7614577581446714\nIteration:  17000\nAccuracy:  0.7702926559911651\nIteration:  18000\nAccuracy:  0.7758144671452236\nIteration:  19000\nAccuracy:  0.7774710104914412\nIteration:  20000\nAccuracy:  0.781888459414688\nIteration:  21000\nAccuracy:  0.7863059083379348\nIteration:  22000\nAccuracy:  0.7918277194919934\nIteration:  23000\nAccuracy:  0.7967973495306461\nIteration:  24000\nAccuracy:  0.8023191606847045\nIteration:  25000\nAccuracy:  0.804527885146328\nIteration:  26000\nAccuracy:  0.8028713418001104\nIteration:  27000\nAccuracy:  0.8056322473771397\nIteration:  28000\nAccuracy:  0.8067366096079515\nIteration:  29000\nAccuracy:  0.8078409718387631\n","output_type":"stream"}]},{"cell_type":"code","source":"#creates another testing set\n\nDATADIR = \"/kaggle/input/trainingdata/TrainingData\"\nCATEGORIES = [\"Happy\", \"Sad\"]\n\n# -- switch between testing sets\n\n#DATADIR = \"/kaggle/input\"\n#CATEGORIES = [\"testing\", \"testing2\"]\n\ndata = []\nIMG_SIZE = 50\n\ndef create_training_data():\n    \n    class_num = 0\n    \n    for category in CATEGORIES:\n        path = os.path.join(DATADIR, category)  # path to our files\n        for img in os.listdir(path):\n            img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n            new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n            flattened_pixels = new_array.flatten().tolist()  # Flatten and convert to a Python list\n\n            data.append([class_num] + flattened_pixels)\n        class_num += 1\n            \ncreate_training_data()\n\ndata = np.array(data)\nm, n = data.shape\nnp.random.shuffle(data) # shuffle before splitting into dev and training sets\n\ndata_t = data[0:180].T\nY_t = data_t[0]\nX_t = data_t[1:n]\nX_t = X_t / 255.","metadata":{"execution":{"iopub.status.busy":"2023-09-06T18:44:16.003670Z","iopub.execute_input":"2023-09-06T18:44:16.004117Z","iopub.status.idle":"2023-09-06T18:44:21.403051Z","shell.execute_reply.started":"2023-09-06T18:44:16.004081Z","shell.execute_reply":"2023-09-06T18:44:21.401753Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def make_predictions(X, W1, b1, W2, b2):\n    _, _, _, A2 = forward_prop(W1, b1, W2, b2, X)\n    predictions = get_predictions(A2)\n    return predictions\n\ndef test_prediction(index, W1, b1, W2, b2):\n    current_image = X_t[:, index, None]\n    prediction = make_predictions(X_t[:, index, None], W1, b1, W2, b2)\n    label = Y_t[index]\n    print(\"Prediction: \", prediction)\n    print(\"Label: \", label)\n    \n    current_image = current_image.reshape((50, 50)) * 255\n    plt.gray()\n    plt.imshow(current_image, interpolation='nearest')\n    plt.show()\n    \nfor i in range(3):\n    test_prediction(i, W1, b1, W2, b2)\n\n\ndev_predictions = make_predictions(X_t, W1, b1, W2, b2)\nget_accuracy(dev_predictions, Y_t)","metadata":{"execution":{"iopub.status.busy":"2023-09-08T01:00:28.543911Z","iopub.execute_input":"2023-09-08T01:00:28.544743Z","iopub.status.idle":"2023-09-08T01:00:29.103699Z","shell.execute_reply.started":"2023-09-08T01:00:28.544685Z","shell.execute_reply":"2023-09-08T01:00:29.101510Z"},"trusted":true},"execution_count":1,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[1], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m3\u001b[39m):\n\u001b[0;32m---> 19\u001b[0m     test_prediction(i, \u001b[43mW1\u001b[49m, b1, W2, b2)\n\u001b[1;32m     22\u001b[0m dev_predictions \u001b[38;5;241m=\u001b[39m make_predictions(X_t, W1, b1, W2, b2)\n\u001b[1;32m     23\u001b[0m get_accuracy(dev_predictions, Y_t)\n","\u001b[0;31mNameError\u001b[0m: name 'W1' is not defined"],"ename":"NameError","evalue":"name 'W1' is not defined","output_type":"error"}]},{"cell_type":"code","source":"# saves numpy arrays Weights and Biases for use in forward_prop() to make predictions\nnp.save('Weights1.npy', W1)\nnp.save('Biases1.npy', b1)\nnp.save('Weights2.npy', W2)\nnp.save('Biases2.npy', b2)","metadata":{"execution":{"iopub.status.busy":"2023-09-06T18:44:45.624300Z","iopub.execute_input":"2023-09-06T18:44:45.624707Z","iopub.status.idle":"2023-09-06T18:44:45.631903Z","shell.execute_reply.started":"2023-09-06T18:44:45.624672Z","shell.execute_reply":"2023-09-06T18:44:45.630808Z"},"trusted":true},"execution_count":17,"outputs":[]}]}